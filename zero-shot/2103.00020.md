# Learning Transferable Visual Models From Natural Language Supervision

# Motivation
- Learning image representation from raw text supervision for pre-training task. 
- Task : Caption prediction using the (image, text) pairs collected from the internet.
- Enable zero-shot transfer of the model to downstream tasks.
- Code and weights can be accessed from [LINK](https://github.com/OpenAI/CLIP)

## Reference
1. [Radford, Alec, et al. "Learning transferable visual models from natural language supervision." International Conference on Machine Learning. PMLR, 2021.](https://arxiv.org/abs/2103.00020)
